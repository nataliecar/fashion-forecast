{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nLink to Documentation: https://github.com/ultralytics/yolov5\\n\\nRUN IN TERMINAL BEFORE PROCEEDED IN THE 'fashion-forecast' DIRECTORY:\\n>   pip install ultralytics\\n>   git clone https://github.com/ultralytics/yolov5  \\n>   cd yolov5\\n>   pip install -r requirements.txt  \\n>   cd ..\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Link to Documentation: https://github.com/ultralytics/yolov5\n",
    "\n",
    "RUN IN TERMINAL BEFORE PROCEEDED IN THE 'fashion-forecast' DIRECTORY:\n",
    ">   pip install ultralytics\n",
    ">   git clone https://github.com/ultralytics/yolov5  \n",
    ">   cd yolov5\n",
    ">   pip install -r requirements.txt  \n",
    ">   cd ..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_837/1640762198.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cardon/miniconda3/lib/python3.11/site-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /home/cardon/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2024-4-16 Python-3.11.5 torch-2.2.2+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True) #force_reload=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCODE TO CHANGE DEVICE:\\nmodel.cpu()  # CPU\\nmodel.cuda()  # GPU\\nmodel.to(device)  # i.e. device=torch.device(0)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CODE TO CHANGE DEVICE:\n",
    "model.cpu()  # CPU\n",
    "model.cuda()  # GPU\n",
    "model.to(device)  # i.e. device=torch.device(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('filtered_style_stats.csv')\n",
    " \n",
    "# no of csv files with row size\n",
    "size = 10000\n",
    "k = math.ceil(len(data.index)/size)\n",
    " \n",
    "for i in range(k):\n",
    "    df = data[size*i:size*(i+1)]\n",
    "    df.to_csv(f'./split_csv/style_stats_{i+1}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_list, img_names, seasons_only_csv):\n",
    "    counter = 0\n",
    "    directory = './yolov5/yolov5/runs/exp4/labels/'\n",
    "    for img_name in os.listdir(directory):\n",
    "        if counter == len(seasons_only_csv.index):\n",
    "            break\n",
    "        if img_name not in seasons_only_csv.iloc[:, 0].values:\n",
    "            continue\n",
    "        if counter%((len(seasons_only_csv.index)/100)*5) == 0:\n",
    "            print(f\"Running... {(counter/len(seasons_only_csv.index))*100:.2f}% finished\")\n",
    "        img_path = os.path.join('./yolov5/yolov5/images/', img_name)\n",
    "        pil_img = Image.open(img_path)\n",
    "        np_img = np.array(pil_img)\n",
    "        #plt.imshow(np_img)             # used to display the images\n",
    "        #plt.show()\n",
    "        img_list.append(np_img)\n",
    "        img_names.append(str(img_path))\n",
    "        counter += 1\n",
    "    print(f'Finished with a set of {len(img_list)} images')\n",
    "    return img_list,img_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Takes the current results and saves only the information from the maximum 'person' detections\\ndef prioritize_detections_old(detection_df):\\n    cleaned_df_lst = []\\n    user_grouped = detection_df.groupby('image')\\n    for idx, (username, grp) in enumerate(user_grouped):\\n        person_grp = grp[grp['class name']=='person']\\n        if (person_grp.size() == 0):\\n            continue\\n        if (person_grp.size() == 1):\\n            row = person_grp.iloc[0].tolist()\\n            row.append(idx)\\n            cleaned_df_lst.append(row)\\n            continue\\n        # multiple detections -> choose the highest confidence of person\\n        maxValueIndex = person_grp['confidence'].idxmax()\\n        row = person_grp.iloc[maxValueIndex].tolist()\\n        row.append(idx)\\n        cleaned_df_lst.append(row)\\n\\n    col_names = list(detection_df[0].columns) + ['df_idx']\\n    cleaned_df = pd.DataFrame(cleaned_df_lst, columns = col_names)\\n    return cleaned_df\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Takes the current results and saves only the information from the maximum 'person' detections\n",
    "def prioritize_detections_old(detection_df):\n",
    "    cleaned_df_lst = []\n",
    "    user_grouped = detection_df.groupby('image')\n",
    "    for idx, (username, grp) in enumerate(user_grouped):\n",
    "        person_grp = grp[grp['class name']=='person']\n",
    "        if (person_grp.size() == 0):\n",
    "            continue\n",
    "        if (person_grp.size() == 1):\n",
    "            row = person_grp.iloc[0].tolist()\n",
    "            row.append(idx)\n",
    "            cleaned_df_lst.append(row)\n",
    "            continue\n",
    "        # multiple detections -> choose the highest confidence of person\n",
    "        maxValueIndex = person_grp['confidence'].idxmax()\n",
    "        row = person_grp.iloc[maxValueIndex].tolist()\n",
    "        row.append(idx)\n",
    "        cleaned_df_lst.append(row)\n",
    "\n",
    "    col_names = list(detection_df[0].columns) + ['df_idx']\n",
    "    cleaned_df = pd.DataFrame(cleaned_df_lst, columns = col_names)\n",
    "    return cleaned_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes the current results and saves only the information from the maximum 'person' detections\"\"\"\n",
    "def prioritize_detections(detection_df):\n",
    "    max_confidence = detection_df.groupby(['image'])['confidence'].transform('max')\n",
    "    #print(max_confidence)\n",
    "    cleaned_df = detection_df.loc[detection_df['confidence'] == max_confidence]\n",
    "    #print(cleaned_df)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to crop image in a 1:1 aspect ratio no smaller than 256 pixels centered around the person detection\n",
    "def crop_image(img, xmin, ymin, xmax, ymax): \n",
    "    w, h = (ymax-ymin), (xmax-xmin)\n",
    "    max_dim = max(w, h)\n",
    "    \n",
    "    img = img[xmin:xmax, ymin:ymax]\n",
    "    img_square = np.ones([max_dim,max_dim], dtype=np.uint8)*0 # chose black for the least data insight\n",
    "    background = Image.fromarray(img_square).convert('RGB')\n",
    "    pil_img = Image.fromarray(img)\n",
    "\n",
    "    background.paste(pil_img, (ymin,xmin))\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes the cleaned df data and crops each image to it's detected bounding box dimensions\"\"\"\n",
    "def crop_detections(cleaned_df, TOTAL_IMG):\n",
    "    directory = './yolov5/yolov5/images/'\n",
    "    save_dir = './yolov5/yolov5/crop-images/'\n",
    "    df_idx = 0\n",
    "    for idx, img_name in enumerate(os.listdir(directory)):\n",
    "        if idx % 10000 == 0:\n",
    "            print(f\"{idx/TOTAL_IMG * 100:2f}% photos run through\")\n",
    "            print(f\"{df_idx} cropped images saved\")\n",
    "        if idx == TOTAL_IMG:\n",
    "            break\n",
    "        #print(img_name[:-4] not in cleaned_df['image'].values)\n",
    "        if img_name[:-4] not in cleaned_df['image'].values:\n",
    "            continue\n",
    "        xmin, ymin, xmax, ymax = cleaned_df.iloc[df_idx][['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        pil_img = Image.open(img_path)\n",
    "        np_img = np.array(pil_img)\n",
    "        crop_img = crop_image(np_img, int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "        save_path = os.path.join(save_dir, img_name)\n",
    "        #print(save_path)\n",
    "        crop_img.save(save_path)\n",
    "        df_idx += 1\n",
    "\n",
    "        \n",
    "    return df_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Beginning run\n",
      "\n",
      "Uploading model results to a pandas dataframe\n",
      "Results saved with length 345883\n",
      "\n",
      "Removing all inaccurate and low confidence detections\n",
      "Left with a dataset of 276648 images\n",
      "\n",
      "Performing final image crop\n",
      "0.000000% photos run through\n",
      "0 cropped images saved\n",
      "3.614702% photos run through\n",
      "9822 cropped images saved\n",
      "7.229403% photos run through\n",
      "19705 cropped images saved\n",
      "10.844105% photos run through\n",
      "29526 cropped images saved\n",
      "14.458807% photos run through\n",
      "39384 cropped images saved\n",
      "18.073509% photos run through\n",
      "49223 cropped images saved\n",
      "21.688210% photos run through\n",
      "58935 cropped images saved\n",
      "25.302912% photos run through\n",
      "68787 cropped images saved\n",
      "28.917614% photos run through\n",
      "78620 cropped images saved\n",
      "32.532315% photos run through\n",
      "88460 cropped images saved\n",
      "36.147017% photos run through\n",
      "98183 cropped images saved\n",
      "39.761719% photos run through\n",
      "107948 cropped images saved\n",
      "43.376421% photos run through\n",
      "117617 cropped images saved\n",
      "46.991122% photos run through\n",
      "127384 cropped images saved\n",
      "50.605824% photos run through\n",
      "137234 cropped images saved\n",
      "54.220526% photos run through\n",
      "146992 cropped images saved\n",
      "57.835227% photos run through\n",
      "156806 cropped images saved\n",
      "61.449929% photos run through\n",
      "166666 cropped images saved\n",
      "65.064631% photos run through\n",
      "176503 cropped images saved\n",
      "68.679333% photos run through\n",
      "186249 cropped images saved\n",
      "72.294034% photos run through\n",
      "196075 cropped images saved\n",
      "75.908736% photos run through\n",
      "205870 cropped images saved\n",
      "79.523438% photos run through\n",
      "215634 cropped images saved\n",
      "83.138139% photos run through\n",
      "225408 cropped images saved\n",
      "86.752841% photos run through\n",
      "235240 cropped images saved\n",
      "90.367543% photos run through\n",
      "245067 cropped images saved\n",
      "93.982245% photos run through\n",
      "254781 cropped images saved\n",
      "97.596946% photos run through\n",
      "264569 cropped images saved\n",
      "Cropping complete.\n",
      "271063 saved to './yolov5/yolov5/crop-data/'\n",
      "Execution complete for full dataset :D\n"
     ]
    }
   ],
   "source": [
    "directory = './split_csv/'\n",
    "'''for filename in os.listdir(directory):\n",
    "    print(f\"---------------------------------------\\nBeginning {filename} batch\\n\")\n",
    "    \n",
    "    filepath = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    img_list = []\n",
    "    img_names = []\n",
    "    img_list, img_names = read_images(img_list, img_names, df)\n",
    "\n",
    "    print(f\"\\nRunning the model\")\n",
    "    results = model(img_list)  # inference\n",
    "    results.save() # cropped detections dictionary\n",
    "    #results.show()\n",
    "'''\n",
    "print(f\"---------------------------------------\\nBeginning run\\n\")\n",
    "print(f\"Uploading model results to a pandas dataframe\")\n",
    "detection_df = pd.read_csv(\"yolov5_labels.csv\", header=0)\n",
    "print(f\"Results saved with length {len(detection_df)}\\n\")\n",
    "'''\n",
    "for idx, df in enumerate(detection_df):\n",
    "    person_df = df[df['name']=='person']\n",
    "    print(person_df.index)\n",
    "'''\n",
    "\n",
    "print(f\"Removing all inaccurate and low confidence detections\")\n",
    "cleaned_df = prioritize_detections(detection_df)\n",
    "TOTAL_IMG = len(cleaned_df.index)\n",
    "print(f\"Left with a dataset of {TOTAL_IMG} images\\n\")\n",
    "\n",
    "print(f\"Performing final image crop\")\n",
    "num_saved = crop_detections(cleaned_df, TOTAL_IMG)\n",
    "print(f\"Cropping complete.\\n{num_saved} saved to \\'./yolov5/yolov5/crop-data/\\'\")\n",
    "print(\"Execution complete for full dataset :D\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
