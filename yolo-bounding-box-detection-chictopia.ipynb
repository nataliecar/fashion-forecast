{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nLink to Documentation: https://github.com/ultralytics/yolov5\\n\\nRUN IN TERMINAL BEFORE PROCEEDED IN THE 'fashion-forecast' DIRECTORY:\\n>   pip install ultralytics\\n>   git clone https://github.com/ultralytics/yolov5  \\n>   cd yolov5\\n>   pip install -r requirements.txt  \\n>   cd ..\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Link to Documentation: https://github.com/ultralytics/yolov5\n",
    "\n",
    "RUN IN TERMINAL BEFORE PROCEEDED IN THE 'fashion-forecast' DIRECTORY:\n",
    ">   pip install ultralytics\n",
    ">   git clone https://github.com/ultralytics/yolov5  \n",
    ">   cd yolov5\n",
    ">   pip install -r requirements.txt  \n",
    ">   cd ..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\cardon/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-2-16 Python-3.8.5 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True) #force_reload=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCODE TO CHANGE DEVICE:\\nmodel.cpu()  # CPU\\nmodel.cuda()  # GPU\\nmodel.to(device)  # i.e. device=torch.device(0)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CODE TO CHANGE DEVICE:\n",
    "model.cpu()  # CPU\n",
    "model.cuda()  # GPU\n",
    "model.to(device)  # i.e. device=torch.device(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000ecstaSY000-75818.jpg 000ecstaSY000-75818.jpg False\n",
      "000ecstaSY000-75819.jpg 000ecstaSY000-75819.jpg False\n",
      "000ecstaSY000-75820.jpg 000ecstaSY000-75820.jpg False\n",
      "0011zm-129448.jpg 0011zm-129448.jpg False\n",
      "0011zm-129449.jpg 0011zm-129449.jpg False\n",
      "0011zm-129450.jpg 0011zm-129450.jpg False\n",
      "0011zm-129451.jpg 0011zm-129451.jpg False\n",
      "0011zm-129452.jpg 0011zm-129452.jpg False\n",
      "0011zm-129453.jpg 0011zm-129453.jpg False\n",
      "0011zm-129454.jpg 0011zm-129454.jpg False\n",
      "0011zm-129455.jpg 0011zm-129455.jpg False\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "img_names = []\n",
    "directory = '../unpack-data/'\n",
    "#trial_size = 10\n",
    "seasons_only_csv = pd.read_csv('filtered_style_stats.csv')\n",
    "counter = 0\n",
    "for idx, img_name in enumerate(os.listdir(directory)):\n",
    "    if seasons_only_csv['new_pic_name'].iloc[idx] != img_name:\n",
    "        continue\n",
    "    #if counter == trial_size:\n",
    "    #    break\n",
    "    img_path = os.path.join(directory, img_name)\n",
    "    pil_img = Image.open(img_path)\n",
    "    np_img = np.array(pil_img)\n",
    "    #plt.imshow(np_img)             # used to display the images\n",
    "    #plt.show()\n",
    "    img_list.append(np_img)\n",
    "    img_names.append(str(img_path))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 10 images to \u001b[1mruns\\detect\\exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model(img_list)  # inference\n",
    "results.save()   # cropped detections dictionary\n",
    "#results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor idx, df in enumerate(detection_df):\\n    person_df = df[df['name']=='person']\\n    print(person_df.index)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_df = results.pandas().xyxy\n",
    "print(len(detection_df))\n",
    "'''\n",
    "for idx, df in enumerate(detection_df):\n",
    "    person_df = df[df['name']=='person']\n",
    "    print(person_df.index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Takes the current results and saves only the information from the maximum 'person' detections\"\"\"\n",
    "\n",
    "cleaned_df_lst = []\n",
    "for idx, df in enumerate(detection_df):\n",
    "    person_df = df[df['name']=='person']\n",
    "    if person_df.empty == True:\n",
    "        continue\n",
    "    if (len(person_df.index) == 1):\n",
    "        row = person_df.iloc[0].tolist()\n",
    "        row.append(idx)\n",
    "        cleaned_df_lst.append(row)\n",
    "        continue\n",
    "    # multiple detections -> choose the highest confidence of person\n",
    "    maxValueIndex = person_df['confidence'].idxmax()\n",
    "    row = person_df.iloc[maxValueIndex].tolist()\n",
    "    row.append(idx)\n",
    "    cleaned_df_lst.append(row)\n",
    "\n",
    "col_names = list(detection_df[0].columns) + ['df_idx']\n",
    "cleaned_df = pd.DataFrame(cleaned_df_lst, columns = col_names)\n",
    "print(len(cleaned_df.index))\n",
    "#print(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes the cleaned df data and crops each image to it's detected bounding box dimensions\"\"\"\n",
    "directory = 'C:/Users/cardon/OneDrive - Rensselaer Polytechnic Institute/SEM8/RCOS/unpack-data'\n",
    "save_dir = 'C:/Users/cardon/OneDrive - Rensselaer Polytechnic Institute/SEM8/RCOS/crop-data'\n",
    "df_idx = 0\n",
    "for idx, img_name in enumerate(os.listdir(directory)):\n",
    "    if idx == 8:\n",
    "        break\n",
    "    if idx not in cleaned_df['df_idx'].values:\n",
    "        continue\n",
    "\n",
    "    xmin, ymin, xmax, ymax = cleaned_df.loc[df_idx][['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "    #print(int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "    df_idx += 1\n",
    "\n",
    "    img_path = os.path.join(directory, img_name)\n",
    "    #print(img_path)\n",
    "    pil_img = Image.open(img_path)\n",
    "    np_img = np.array(pil_img)\n",
    "    #plt.imshow(np_img)             \n",
    "    #plt.show()\n",
    "    crop_img = np_img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "    #plt.imshow(crop_img)             \n",
    "    #plt.show()\n",
    "    save_path = os.path.join(save_dir, (img_name+'.jpg'))\n",
    "    save_im = Image.fromarray(crop_img)\n",
    "    save_im.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
