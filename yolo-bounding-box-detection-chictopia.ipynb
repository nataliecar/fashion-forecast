{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nLink to Documentation: https://github.com/ultralytics/yolov5\\n\\nRUN IN TERMINAL BEFORE PROCEEDED IN THE 'fashion-forecast' DIRECTORY:\\n>   pip install ultralytics\\n>   git clone https://github.com/ultralytics/yolov5  \\n>   cd yolov5\\n>   pip install -r requirements.txt  \\n>   cd ..\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Link to Documentation: https://github.com/ultralytics/yolov5\n",
    "\n",
    "RUN IN TERMINAL BEFORE PROCEEDED IN THE 'fashion-forecast' DIRECTORY:\n",
    ">   pip install ultralytics\n",
    ">   git clone https://github.com/ultralytics/yolov5  \n",
    ">   cd yolov5\n",
    ">   pip install -r requirements.txt  \n",
    ">   cd ..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\cardon/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-2-16 Python-3.8.5 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True) #force_reload=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCODE TO CHANGE DEVICE:\\nmodel.cpu()  # CPU\\nmodel.cuda()  # GPU\\nmodel.to(device)  # i.e. device=torch.device(0)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CODE TO CHANGE DEVICE:\n",
    "model.cpu()  # CPU\n",
    "model.cuda()  # GPU\n",
    "model.to(device)  # i.e. device=torch.device(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('filtered_style_stats.csv')\n",
    " \n",
    "# no of csv files with row size\n",
    "size = 10000\n",
    "k = math.ceil(len(data.index)/size)\n",
    " \n",
    "for i in range(k):\n",
    "    df = data[size*i:size*(i+1)]\n",
    "    df.to_csv(f'./split_csv/style_stats_{i+1}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_list, img_names, seasons_only_csv):\n",
    "    counter = 0\n",
    "    directory = '../unpack-data/'\n",
    "    for img_name in os.listdir(directory):\n",
    "        if counter == len(seasons_only_csv.index):\n",
    "            break\n",
    "        if img_name not in seasons_only_csv.iloc[:, 0].values:\n",
    "            continue\n",
    "        if counter%((len(seasons_only_csv.index)/100)*5) == 0:\n",
    "            print(f\"Running... {(counter/len(seasons_only_csv.index))*100:.2f}% finished\")\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        pil_img = Image.open(img_path)\n",
    "        np_img = np.array(pil_img)\n",
    "        #plt.imshow(np_img)             # used to display the images\n",
    "        #plt.show()\n",
    "        img_list.append(np_img)\n",
    "        img_names.append(str(img_path))\n",
    "        counter += 1\n",
    "    print(f'Finished with a set of {len(img_list)} images')\n",
    "    return img_list,img_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes the current results and saves only the information from the maximum 'person' detections\"\"\"\n",
    "def prioritize_detections(detection_df):\n",
    "    cleaned_df_lst = []\n",
    "    for idx, df in enumerate(detection_df):\n",
    "        person_df = df[df['name']=='person']\n",
    "        if person_df.empty == True:\n",
    "            continue\n",
    "        if (len(person_df.index) == 1):\n",
    "            row = person_df.iloc[0].tolist()\n",
    "            row.append(idx)\n",
    "            cleaned_df_lst.append(row)\n",
    "            continue\n",
    "        # multiple detections -> choose the highest confidence of person\n",
    "        maxValueIndex = person_df['confidence'].idxmax()\n",
    "        row = person_df.iloc[maxValueIndex].tolist()\n",
    "        row.append(idx)\n",
    "        cleaned_df_lst.append(row)\n",
    "\n",
    "    col_names = list(detection_df[0].columns) + ['df_idx']\n",
    "    cleaned_df = pd.DataFrame(cleaned_df_lst, columns = col_names)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to crop image in a 1:1 aspect ratio no smaller than 256 pixels centered around the person detection\n",
    "def crop_image(img, xmin, ymin, xmax, ymax): \n",
    "    max_dim = max((xmax-xmin), (ymax-ymin))\n",
    "    img = img[ymin:ymax, xmin:xmax]\n",
    "    img_square = np.ones([max_dim+1,max_dim+1], dtype=np.uint8)*127 # chose gray for the least data insight\n",
    "    xmin, xmax, ymin, ymax = 0, (xmax-xmin), 0, (ymax-ymin) # left centered for now\n",
    "    img_square[ymin:ymax, xmin:xmax] = img\n",
    "    return img_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes the cleaned df data and crops each image to it's detected bounding box dimensions\"\"\"\n",
    "def crop_detections(cleaned_df, TOTAL_IMG):\n",
    "    directory = '../unpack-data/'\n",
    "    save_dir = '../crop-data/'\n",
    "    df_idx = 0\n",
    "    for idx, img_name in enumerate(os.listdir(directory)):\n",
    "        if idx == TOTAL_IMG:\n",
    "            break\n",
    "        if idx not in cleaned_df['df_idx'].values:\n",
    "            continue\n",
    "\n",
    "        xmin, ymin, xmax, ymax = cleaned_df.loc[df_idx][['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "        #print(int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        pil_img = Image.open(img_path).convert(\"L\")\n",
    "        np_img = np.array(pil_img)\n",
    "        crop_img = crop_image(np_img, int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "        #plt.imshow(crop_img, cmap='gray')\n",
    "\n",
    "        save_path = os.path.join(save_dir, (img_name+'.jpg'))\n",
    "        save_im = Image.fromarray(crop_img)\n",
    "        save_im.save(save_path)\n",
    "        df_idx += 1\n",
    "    return df_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Beginning style_stats_1.csv batch\n",
      "\n",
      "Running... 0.00% finished\n",
      "Running... 5.00% finished\n",
      "Running... 10.00% finished\n",
      "Running... 15.00% finished\n",
      "Running... 20.00% finished\n",
      "Running... 25.00% finished\n",
      "Running... 30.00% finished\n",
      "Running... 35.00% finished\n",
      "Running... 40.00% finished\n",
      "Running... 45.00% finished\n",
      "Running... 50.00% finished\n",
      "Running... 55.00% finished\n",
      "Running... 60.00% finished\n",
      "Running... 65.00% finished\n",
      "Running... 70.00% finished\n",
      "Running... 75.00% finished\n",
      "Running... 80.00% finished\n",
      "Running... 85.00% finished\n",
      "Running... 90.00% finished\n",
      "Running... 95.00% finished\n",
      "Finished with a set of 1000 images\n",
      "\n",
      "Running the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1000 images to \u001b[1mruns\\detect\\exp6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model results to a pandas dataframe\n"
     ]
    }
   ],
   "source": [
    "directory = './split_csv/'\n",
    "for filename in os.listdir(directory):\n",
    "    print(f\"---------------------------------------\\nBeginning {filename} batch\\n\")\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    img_list = []\n",
    "    img_names = []\n",
    "    img_list, img_names = read_images(img_list, img_names, df)\n",
    "\n",
    "    print(f\"\\nRunning the model\")\n",
    "    results = model(img_list)  # inference\n",
    "    results.save() # cropped detections dictionary\n",
    "    #results.show()\n",
    "\n",
    "    print(f\"Saving model results to a pandas dataframe\")\n",
    "    detection_df = results.pandas().xyxy\n",
    "    print(f\"Model saved with length {len(detection_df)}\\n\")\n",
    "    '''\n",
    "    for idx, df in enumerate(detection_df):\n",
    "        person_df = df[df['name']=='person']\n",
    "        print(person_df.index)\n",
    "    '''\n",
    "\n",
    "    print(f\"Removing all inaccurate and low confidence detections\")\n",
    "    cleaned_df = prioritize_detections(detection_df)\n",
    "    TOTAL_IMG = len(cleaned_df.index)\n",
    "    print(f\"Left with a dataset of {TOTAL_IMG} images\\n\")\n",
    "\n",
    "    print(f\"Performing final image crop\")\n",
    "    num_saved = crop_detections(cleaned_df, TOTAL_IMG)\n",
    "    print(f\"Cropping complete.\\n{num_saved} saved to \\'../crop-data\\'\\n{filename} batch complete.\\n\")\n",
    "    break\n",
    "\n",
    "print(\"Execution complete for full dataset :D\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
