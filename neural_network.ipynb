{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, utils, models\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True).to(device)\n",
    "\n",
    "# Freezing the base model layers to prevent retraining\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on the Resnet Model:\n",
    "\n",
    "** convert images to b&w\n",
    "- Requires input images dimensions (256,256) ** resize our images\n",
    "- My additional fully connected layer needs dimensions (2048,10) - 10 for the 10 classes for the 10 style types (--)\n",
    "- Image preprocessing requires:\n",
    "  1. (224,224) center crop\n",
    "  2. image is normalized with mean = 255*[0.485, 0.456, 0.406] and\n",
    "  std = 255*[0.229, 0.224, 0.225]\n",
    "  3. transpose it from HWC to CHW layout\n",
    "- Post-processing involves calculating the softmax probability scores for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 10\n",
    "model.fc = torch.nn.Linear(512, classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.NLLLoss # multi-class classification model loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_file,      # images could be provided with in a series of directories\n",
    "                 root_dir,     # images could be provided as a list as well\n",
    "                 transform = transforms.ToTensor()):  # provide transformation to apply to each image\n",
    "      \"\"\"\n",
    "      Organize the images and the associated labels into two lists.  Potentially create additional\n",
    "      lists if more complicated information is need.  Important note: images are NOT\n",
    "      read and stored in this initializer.  They are read in __getitem__ as needed.\n",
    "      \"\"\"\n",
    "      self.csv_file = csv_file # path of csv file\n",
    "      self.root_dir = root_dir # directory the photos are in\n",
    "      self.images = pd.read_csv(self.csv_file)\n",
    "      # Record the transform that may need to be applied.\n",
    "      self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Return a tuple with the data, ground truth label, and any other data\n",
    "        associated with a single image.\n",
    "        '''\n",
    "        img_name = self.images.iloc[idx, 0] # name of image in 1st column\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        im = Image.open(img_name)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            im = self.transform(im)\n",
    "\n",
    "        \"\"\"\n",
    "        label encodes season\n",
    "        season = {\n",
    "            0: 'spring'\n",
    "            1: 'summer'\n",
    "            2: 'fall'\n",
    "            3: 'winter'  \n",
    "        }\n",
    "        \"\"\"\n",
    "        label = self.images.iloc[idx, 1]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1), \\\n",
    "                                      transforms.ToTensor(), transforms.Resize((224, 224)), \\\n",
    "                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "dataset = MyDataset(csv_file='C:\\Users\\cardon\\OneDrive - Rensselaer Polytechnic Institute\\SEM8\\RCOS\\fashion-forecast\\SFS_metadata_new.csv',\n",
    "                    root_dir='C:\\Users\\cardon\\OneDrive - Rensselaer Polytechnic Institute\\SEM8\\RCOS\\crop-data',\n",
    "                    transform=image_transforms)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.7, 0.15, 0.15], generator=torch.Generator())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
